# Robot Vision System - FastAPI Server + Raspberry Pi Client

A client-server robot vision system using **YOLOv11n** for object detection and tracking. The server processes images and returns navigation commands; the Raspberry Pi client captures images and controls motors.

**NEW: Pi Stream Server** - Stream video from Pi that anyone on the network can view!

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              NETWORK                                        â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   RASPBERRY PI      â”‚   HTTP/REST  â”‚         SERVER (PC/Cloud)       â”‚  â”‚
â”‚  â”‚   (client_rpi.py)   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚         (server.py)             â”‚  â”‚
â”‚  â”‚                     â”‚              â”‚                                 â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   Images     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚    Camera     â”‚â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  â”‚      YOLOv11n Model      â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                     â”‚              â”‚               â”‚                 â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   Commands   â”‚               â–¼                 â”‚  â”‚
â”‚  â”‚  â”‚    Motors     â”‚â—„â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚   (Arduino)   â”‚  â”‚   (JSON)    â”‚â”‚  â”‚  Detection + Tracking    â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                     â”‚              â”‚               â”‚                 â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚              â”‚               â–¼                 â”‚  â”‚
â”‚  â”‚  â”‚    Servo      â”‚  â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚  (Camera Pan) â”‚  â”‚              â”‚  â”‚   Direction Calculation   â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Files

| File | Location | Description |
|------|----------|-------------|
| `server.py` | Server (PC/Cloud) | FastAPI server with YOLO processing |
| `client_rpi.py` | Raspberry Pi | Image capture + motor control client |
| `rpi_stream_server.py` | Raspberry Pi | **Video streaming server** (view from any browser!) |
| `requirements.txt` | Both | Python dependencies |

---

## ğŸš€ Quick Start

### 1. Server Setup (PC with GPU recommended)

```bash
# Install dependencies
pip install -r requirements.txt

# Run server
python server.py
# or with uvicorn for production:
uvicorn server:app --host 0.0.0.0 --port 8000
```

Server will be available at `http://YOUR_IP:8000`

### 2. Raspberry Pi Setup

```bash
# Install dependencies
pip install -r requirements.txt

# (Optional) For Pi Camera support
pip install picamera2
```

**Note:** USB webcam is the default camera. Use `--picamera` flag to use Pi camera.

#### Option A: Run Stream Server (anyone can view video)

```bash
# USB Webcam (default)
python rpi_stream_server.py --port 8080

# If you have multiple USB cameras, specify index
python rpi_stream_server.py --port 8080 --camera 1

# Pi Camera (if needed)
python rpi_stream_server.py --port 8080 --picamera
```

Now anyone can view the stream at: `http://PI_IP:8080/`

#### Option B: Run Client (sends images to vision server)

```bash
# USB Webcam (default)
python client_rpi.py --server http://SERVER_IP:8000 --mode realtime --target person

# Pi Camera (if needed)
python client_rpi.py --server http://SERVER_IP:8000 --mode realtime --picamera
```

---

## ğŸ”Œ API Endpoints

### Vision Server (PC - port 8000)

#### Health Check
```http
GET /
```
Returns server status and available classes.

#### Get All Classes
```http
GET /classes
```
Returns all 80 COCO class names.

---

### Pi Stream Server (Raspberry Pi - port 8080)

| Endpoint | Description |
|----------|-------------|
| `GET /` | Web page with video player |
| `GET /video_feed` | MJPEG stream (for browsers/VLC) |
| `GET /snapshot` | Single JPEG image |
| `GET /api/frame` | Raw JPEG for API consumption |
| `GET /api/status` | Camera status and FPS |

**View in browser:** `http://PI_IP:8080/`

**View in VLC:** `vlc http://PI_IP:8080/video_feed`

---

### Real-time Detection
```http
POST /detect/realtime
```

Single image detection with tracking.

**Request:**
| Field | Type | Description |
|-------|------|-------------|
| `image` | File | JPEG/PNG image |
| `target_class` | string | Object to track (default: "person") |
| `confidence` | float | Threshold 0-1 (default: 0.4) |
| `track` | bool | Enable tracking (default: true) |

**Response:**
```json
{
  "success": true,
  "direction": "left",
  "target_found": true,
  "target_detection": {
    "class_name": "person",
    "confidence": 0.92,
    "bbox": [100, 150, 300, 400],
    "centroid": [200, 275],
    "area": 50000,
    "area_ratio": 0.163
  },
  "tracking": {
    "object_id": 0,
    "velocity": [25.5, -10.2],
    "frames_tracked": 15
  },
  "distance_ratio": 0.163,
  "reached": false,
  "message": "Target 'person' found - left"
}
```

---

### Multi-view Detection
```http
POST /detect/multiview
```

3-image scan with 5-direction output.

**Request:**
| Field | Type | Description |
|-------|------|-------------|
| `image_left` | File | Left view image |
| `image_center` | File | Center view image |
| `image_right` | File | Right view image |
| `target_class` | string | Object to find (default: "person") |
| `confidence` | float | Threshold 0-1 (default: 0.4) |

**Response:**
```json
{
  "success": true,
  "direction": "right",
  "direction_angle": 135,
  "target_found": true,
  "views_with_target": ["center", "right"],
  "prominence": {
    "left": 0.0,
    "center": 0.35,
    "right": 0.65
  },
  "best_view": "right",
  "target_area_ratio": 0.13,
  "reached": false,
  "obstacles_detected": 2,
  "message": "Direction: right (135Â°) - Target in: center, right"
}
```

---

### Simple Detection
```http
POST /detect/single
```

Basic detection - returns all objects, no tracking.

**Response:**
```json
{
  "success": true,
  "count": 5,
  "detections": [
    {"class_name": "person", "confidence": 0.92, "bbox": [...], ...},
    {"class_name": "chair", "confidence": 0.85, "bbox": [...], ...}
  ]
}
```

---

### Reset Tracker
```http
POST /tracker/reset
```

Clears tracking history (useful when target changes).

---

### Stream Processing (Server pulls from Pi)

The vision server can pull frames directly from Pi's stream:

#### Start Stream Processing
```http
POST /stream/start
Content-Type: application/json

{
  "stream_url": "http://192.168.1.105:8080",
  "target_class": "person",
  "confidence": 0.4,
  "interval_ms": 100
}
```

#### Get Stream Status
```http
GET /stream/status
```

#### Get Latest Direction (for polling)
```http
GET /stream/direction
```

#### Stop Stream
```http
POST /stream/stop
```

---

## ğŸ¯ Detection Modes

### Mode 1: Real-time Tracking (Client Push)

Continuous single-image detection with object tracking. Pi captures and sends images.

```bash
python client_rpi.py --mode realtime --target person
```

**Features:**
- Centroid-based tracking across frames
- Velocity calculation for prediction
- 3-zone direction (left/center/right)
- Distance estimation via area ratio

**Flow:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Capture â”‚ â”€â”€â–º â”‚  Send   â”‚ â”€â”€â–º â”‚ Process â”‚ â”€â”€â–º â”‚  Move   â”‚
â”‚  Frame  â”‚     â”‚ to API  â”‚     â”‚ (YOLO)  â”‚     â”‚ Motors  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â–²                                               â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        ~30 FPS loop
```

---

### Mode 2: Multi-view Object Finding (Client Push)

3-view scan with 5-direction navigation.

```bash
python client_rpi.py --mode multiview --target person
```

---

### Mode 3: Stream Processing (Server Pull)

Server pulls frames from Pi's stream server. Good for centralized control.

**On Raspberry Pi:**
```bash
python rpi_stream_server.py --port 8080
```

**On PC (start processing via API):**
```bash
curl -X POST http://localhost:8000/stream/start \
  -H "Content-Type: application/json" \
  -d '{"stream_url": "http://PI_IP:8080", "target_class": "person"}'
```

**Poll for direction:**
```bash
curl http://localhost:8000/stream/direction
# Returns: {"direction": "left", "target_found": true, "timestamp": 1703520000}
```

**5 Directions:**
```
          180Â° arc
â•”â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•—
â•‘FAR_LEFT â•‘  LEFT   â•‘ CENTER  â•‘  RIGHT  â•‘FAR_RIGHTâ•‘
â•‘   0Â°    â•‘   45Â°   â•‘   90Â°   â•‘  135Â°   â•‘  180Â°   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•
```

**Flow:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Rotate Servo  â”‚
â”‚ Leftâ†’Centerâ†’Right
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Capture 3     â”‚
â”‚ Images        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Send to API   â”‚
â”‚ /detect/multiview
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Calculate     â”‚
â”‚ 5-Direction   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Move Robot    â”‚
â”‚ (ML/MC/MR/...)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Direction Calculation

### Real-time (3 zones)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             â”‚                             â”‚             â”‚
â”‚    LEFT     â”‚          CENTER             â”‚    RIGHT    â”‚
â”‚   0-35%     â”‚         35%-65%             â”‚  65%-100%   â”‚
â”‚             â”‚                             â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Multi-view (5 directions)

Based on **weighted prominence** across views:

```python
weighted = (-1 Ã— left) + (0 Ã— center) + (1 Ã— right)

# Mapping:
#  -1.0 to -0.6  â†’  FAR_LEFT   (0Â°)
#  -0.6 to -0.2  â†’  LEFT       (45Â°)
#  -0.2 to  0.2  â†’  CENTER     (90Â°)
#   0.2 to  0.6  â†’  RIGHT      (135Â°)
#   0.6 to  1.0  â†’  FAR_RIGHT  (180Â°)
```

---

## ğŸ”§ Configuration

### Client Command Line

```bash
python client_rpi.py \
  --server http://192.168.1.100:8000 \
  --port /dev/ttyUSB0 \
  --target person \
  --mode realtime \
  --confidence 0.4 \
  --picamera  # Use Pi camera instead of USB webcam
```

| Argument | Default | Description |
|----------|---------|-------------|
| `--server` | localhost:8000 | Server URL |
| `--port` | /dev/ttyUSB0 | Arduino serial port |
| `--target` | person | Object class to track |
| `--mode` | realtime | `realtime` or `multiview` |
| `--confidence` | 0.4 | Detection threshold |
| `--picamera` | false | Use Pi camera |

---

## ğŸ“¡ Arduino Commands

The client sends these commands to Arduino via serial:

### Movement
| Command | Action |
|---------|--------|
| `MFL` | Move Far Left (sharp turn) |
| `ML` | Move Left |
| `MC` | Move Center (straight) |
| `MR` | Move Right |
| `MFR` | Move Far Right (sharp turn) |
| `ST` | Stop |
| `RB` | Rotate 180Â° |

### Servo
| Command | Action |
|---------|--------|
| `SL` | Servo Left |
| `SC` | Servo Center |
| `SR` | Servo Right |
| `PHOTO_ACK` | Photo captured ack |

### Arduino â†’ Pi Messages
| Message | Meaning |
|---------|---------|
| `ROTATION_ACK` | Servo rotation done |
| `OBSTACLE DETECTED` | Ultrasonic triggered |
| `OBSTACLE CLEARED` | Path clear |

---

## ğŸ§ª Testing the API

### Using curl

```bash
# Health check
curl http://localhost:8000/

# Real-time detection
curl -X POST http://localhost:8000/detect/realtime \
  -F "image=@test.jpg" \
  -F "target_class=person" \
  -F "confidence=0.4"

# Multi-view detection
curl -X POST http://localhost:8000/detect/multiview \
  -F "image_left=@left.jpg" \
  -F "image_center=@center.jpg" \
  -F "image_right=@right.jpg" \
  -F "target_class=person"
```

### Using Python

```python
import requests

# Real-time
with open("frame.jpg", "rb") as f:
    resp = requests.post(
        "http://localhost:8000/detect/realtime",
        files={"image": f},
        data={"target_class": "person"}
    )
print(resp.json())

# Multi-view
files = {
    "image_left": open("left.jpg", "rb"),
    "image_center": open("center.jpg", "rb"),
    "image_right": open("right.jpg", "rb"),
}
resp = requests.post(
    "http://localhost:8000/detect/multiview",
    files=files,
    data={"target_class": "person"}
)
print(resp.json())
```

---

## ğŸ“Š API Documentation

FastAPI provides automatic interactive docs:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

---

## ğŸ·ï¸ COCO Classes (80 objects)

| Category | Classes |
|----------|---------|
| **People** | person |
| **Vehicles** | bicycle, car, motorcycle, airplane, bus, train, truck, boat |
| **Animals** | bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe |
| **Accessories** | backpack, umbrella, handbag, tie, suitcase |
| **Sports** | frisbee, skis, snowboard, sports ball, kite, baseball bat, tennis racket |
| **Kitchen** | bottle, wine glass, cup, fork, knife, spoon, bowl |
| **Food** | banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake |
| **Furniture** | chair, couch, potted plant, bed, dining table, toilet |
| **Electronics** | tv, laptop, mouse, remote, keyboard, cell phone |
| **Appliances** | microwave, oven, toaster, sink, refrigerator |
| **Indoor** | book, clock, vase, scissors, teddy bear, hair drier, toothbrush |

âš ï¸ **Note**: `door` is NOT in COCO. Train a custom model if needed.

---

## ğŸ“ˆ Performance

| Metric | Server (GPU) | Server (CPU) |
|--------|--------------|--------------|
| Detection latency | ~30ms | ~150ms |
| Requests/sec | ~30 | ~6 |
| Model memory | ~500MB | ~500MB |

---

## ğŸ”® Future Improvements

- [ ] WebSocket for real-time streaming
- [ ] Multiple client support with session IDs
- [ ] Redis for distributed tracking state
- [ ] Custom model training for doors
- [ ] Docker deployment

---

## ğŸ“„ License

MIT License
